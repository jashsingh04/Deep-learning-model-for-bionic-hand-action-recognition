{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, Conv2D, MaxPooling2D,Dropout,MaxPooling1D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\Dataset\\Surya.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features_ch1 =  dataset[dataset['EMG'] == 'EMG1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 1002)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_features_ch1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_labels = dataset_features_ch1['label']\n",
    "dataset_features = dataset_features_ch1.drop(columns=['label','EMG'],axis=1)\n",
    "dataset_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataset_labels)\n",
    "encoded_Y = encoder.transform(dataset_labels)\n",
    "y = np_utils.to_categorical(encoded_Y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 1000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(dataset_features[:])\n",
    "x = x.reshape(x.shape[0],x.shape[1],1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(x).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "model = Sequential()\n",
    "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_r.shape[1],x_r.shape[2])))\n",
    "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x.shape[0],x.shape[1])))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x.shape[1],1)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 1000, 1) (180, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 998, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 996, 64)           12352     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 996, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 498, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 31872)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               3187300   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,200,514\n",
      "Trainable params: 3,200,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = {'accuracy':[], 'loss':[], 'val_accuracy':[], 'val_loss':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 120 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 1s 8ms/sample - loss: 47.7969 - acc: 0.2083 - val_loss: 296.9334 - val_acc: 0.1667\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 295.5939 - acc: 0.2250 - val_loss: 323.3093 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 286.3780 - acc: 0.3000 - val_loss: 197.6731 - val_acc: 0.1667\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 153.1766 - acc: 0.2667 - val_loss: 54.3818 - val_acc: 0.3667\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 41.3991 - acc: 0.4750 - val_loss: 39.8454 - val_acc: 0.1667\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 29.1180 - acc: 0.3250 - val_loss: 22.5318 - val_acc: 0.2833\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 16.6869 - acc: 0.4250 - val_loss: 14.2440 - val_acc: 0.3167\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 10.8010 - acc: 0.4583 - val_loss: 6.9971 - val_acc: 0.4333\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 5.0510 - acc: 0.5333 - val_loss: 3.6744 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.8799 - acc: 0.6833 - val_loss: 3.2286 - val_acc: 0.5167\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.7851 - acc: 0.5750 - val_loss: 2.3963 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.2076 - acc: 0.5750 - val_loss: 1.7529 - val_acc: 0.6333\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.6710 - acc: 0.7333 - val_loss: 1.5065 - val_acc: 0.7167\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.6026 - acc: 0.7417 - val_loss: 1.4418 - val_acc: 0.5333\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.6166 - acc: 0.7917 - val_loss: 1.4105 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.6255 - acc: 0.8000 - val_loss: 1.3388 - val_acc: 0.5333\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.5857 - acc: 0.8083 - val_loss: 1.2130 - val_acc: 0.5500\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.5021 - acc: 0.8000 - val_loss: 1.0785 - val_acc: 0.6167\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.4405 - acc: 0.8250 - val_loss: 0.9813 - val_acc: 0.6500\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.3788 - acc: 0.8333 - val_loss: 0.9056 - val_acc: 0.6500\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.3413 - acc: 0.8333 - val_loss: 0.8114 - val_acc: 0.6667\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.2755 - acc: 0.8500 - val_loss: 0.7567 - val_acc: 0.6667\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.2342 - acc: 0.8833 - val_loss: 0.7332 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.1874 - acc: 0.9000 - val_loss: 0.7081 - val_acc: 0.6833\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.1452 - acc: 0.9667 - val_loss: 0.6400 - val_acc: 0.7833\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0937 - acc: 1.0000 - val_loss: 0.6535 - val_acc: 0.7667\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0642 - acc: 0.9917 - val_loss: 0.7133 - val_acc: 0.7667\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0399 - acc: 0.9917 - val_loss: 0.7403 - val_acc: 0.7833\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0329 - acc: 0.9917 - val_loss: 0.7323 - val_acc: 0.7667\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.7422 - val_acc: 0.7667\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.7608 - val_acc: 0.7667\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.7833\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7836 - val_acc: 0.7833\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7953 - val_acc: 0.7667\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.8064 - val_acc: 0.7833\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.8207 - val_acc: 0.7833\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8387 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8928 - val_acc: 0.7500\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9148 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9353 - val_acc: 0.7667\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9532 - val_acc: 0.7667\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9670 - val_acc: 0.7667\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9788 - val_acc: 0.7833\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9793 - val_acc: 0.7833\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9863 - val_acc: 0.7833\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.7833\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.6703e-04 - acc: 1.0000 - val_loss: 0.9976 - val_acc: 0.7833\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.9702e-04 - acc: 1.0000 - val_loss: 1.0000 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9964 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 9.9186e-04 - acc: 1.0000 - val_loss: 0.9911 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 8.3858e-04 - acc: 1.0000 - val_loss: 0.9856 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9806 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9781 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 8.7245e-04 - acc: 1.0000 - val_loss: 0.9888 - val_acc: 0.7833\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9862 - val_acc: 0.7833\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 4.2780e-04 - acc: 1.0000 - val_loss: 0.9805 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 6.3095e-04 - acc: 1.0000 - val_loss: 0.9892 - val_acc: 0.7833\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.9715e-04 - acc: 1.0000 - val_loss: 1.0017 - val_acc: 0.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 5.2569e-04 - acc: 1.0000 - val_loss: 1.0095 - val_acc: 0.7833\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 4.0243e-04 - acc: 1.0000 - val_loss: 1.0068 - val_acc: 0.7833\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 4.2433e-04 - acc: 1.0000 - val_loss: 1.0060 - val_acc: 0.7833\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.1638e-04 - acc: 1.0000 - val_loss: 1.0066 - val_acc: 0.7833\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.9433e-04 - acc: 1.0000 - val_loss: 1.0029 - val_acc: 0.7833\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 5.6652e-04 - acc: 1.0000 - val_loss: 1.0054 - val_acc: 0.7833\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 4.9035e-04 - acc: 1.0000 - val_loss: 1.0259 - val_acc: 0.7833\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.8879e-04 - acc: 1.0000 - val_loss: 1.0501 - val_acc: 0.7833\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.0811e-04 - acc: 1.0000 - val_loss: 1.0619 - val_acc: 0.7833\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.4119e-04 - acc: 1.0000 - val_loss: 1.0895 - val_acc: 0.7833\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.7184e-04 - acc: 1.0000 - val_loss: 1.0898 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.9361e-04 - acc: 1.0000 - val_loss: 1.0692 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.9134e-04 - acc: 1.0000 - val_loss: 1.0752 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.4258e-04 - acc: 1.0000 - val_loss: 1.1053 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.9005e-04 - acc: 1.0000 - val_loss: 1.1507 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.9151e-04 - acc: 1.0000 - val_loss: 1.1851 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.7181e-04 - acc: 1.0000 - val_loss: 1.2363 - val_acc: 0.7833\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.6780e-04 - acc: 1.0000 - val_loss: 1.2881 - val_acc: 0.7833\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.2090e-04 - acc: 1.0000 - val_loss: 1.3122 - val_acc: 0.7667\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.3556e-04 - acc: 1.0000 - val_loss: 1.2767 - val_acc: 0.7667\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1733e-04 - acc: 1.0000 - val_loss: 1.2435 - val_acc: 0.7833\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.8386e-04 - acc: 1.0000 - val_loss: 1.2014 - val_acc: 0.7833\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1989e-04 - acc: 1.0000 - val_loss: 1.1800 - val_acc: 0.7833\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4575e-04 - acc: 1.0000 - val_loss: 1.1712 - val_acc: 0.7833\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.5029e-04 - acc: 1.0000 - val_loss: 1.1670 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.0555e-04 - acc: 1.0000 - val_loss: 1.1744 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.5276e-04 - acc: 1.0000 - val_loss: 1.1894 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.1212e-05 - acc: 1.0000 - val_loss: 1.2024 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.6771e-04 - acc: 1.0000 - val_loss: 1.2137 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1976e-04 - acc: 1.0000 - val_loss: 1.2293 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.5688e-05 - acc: 1.0000 - val_loss: 1.2440 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.9858e-05 - acc: 1.0000 - val_loss: 1.2593 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.0215e-04 - acc: 1.0000 - val_loss: 1.2739 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.4629e-05 - acc: 1.0000 - val_loss: 1.2857 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.7476e-05 - acc: 1.0000 - val_loss: 1.2911 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.9460e-05 - acc: 1.0000 - val_loss: 1.2876 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.1110e-05 - acc: 1.0000 - val_loss: 1.2797 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.6365e-05 - acc: 1.0000 - val_loss: 1.2789 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.3324e-05 - acc: 1.0000 - val_loss: 1.2839 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.8807e-05 - acc: 1.0000 - val_loss: 1.2890 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.0930e-04 - acc: 1.0000 - val_loss: 1.2850 - val_acc: 0.8000\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 120 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.7397 - acc: 0.8833 - val_loss: 5.2472e-04 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.1068 - acc: 0.9667 - val_loss: 0.0693 - val_acc: 0.9667\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.2348 - acc: 0.9167 - val_loss: 0.0551 - val_acc: 0.9667\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0913 - acc: 0.9667 - val_loss: 0.1144 - val_acc: 0.9333\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.1050 - acc: 0.9667 - val_loss: 0.0551 - val_acc: 0.9833\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9833\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 0.9833\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0378 - acc: 0.9750 - val_loss: 0.0809 - val_acc: 0.9833\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0783 - val_acc: 0.9833\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0748 - val_acc: 0.9833\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0755 - val_acc: 0.9833\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9833\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9667\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9667\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9667\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1287 - val_acc: 0.9500\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1431 - val_acc: 0.9500\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9333\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9500\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9833\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.5434e-04 - acc: 1.0000 - val_loss: 0.1232 - val_acc: 0.9833\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9833\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.9885e-04 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9833\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.9827e-04 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9833\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.8169e-04 - acc: 1.0000 - val_loss: 0.1271 - val_acc: 0.9833\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.1099e-04 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 0.9833\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.2183e-04 - acc: 1.0000 - val_loss: 0.1289 - val_acc: 0.9833\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.6950e-04 - acc: 1.0000 - val_loss: 0.1296 - val_acc: 0.9667\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.7447e-04 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 0.9667\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.1842e-04 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9667\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.3952e-04 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9667\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.9729e-04 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9667\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.1668e-04 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9667\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.5140e-04 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9667\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.2377e-04 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9667\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.1226e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9667\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.3146e-04 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9667\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.0939e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9667\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4423e-04 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 0.9667\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.7256e-04 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9667\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.4517e-04 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9667\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.6899e-04 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9667\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.4671e-04 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9667\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.4765e-04 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 0.9667\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.7785e-04 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9667\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.4193e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9667\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.6322e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9667\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 9.3338e-05 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9667\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 4.2658e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9667\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.7556e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9667\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.2477e-04 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 0.9667\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.2443e-04 - acc: 1.0000 - val_loss: 0.1413 - val_acc: 0.9667\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 9.4123e-05 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9667\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.3750e-04 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9667\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.7690e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9667\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.9302e-05 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9667\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.1329e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9667\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.0402e-04 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9667\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.1271e-04 - acc: 1.0000 - val_loss: 0.1433 - val_acc: 0.9667\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1607e-04 - acc: 1.0000 - val_loss: 0.1435 - val_acc: 0.9667\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2359e-04 - acc: 1.0000 - val_loss: 0.1436 - val_acc: 0.9667\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2699e-04 - acc: 1.0000 - val_loss: 0.1436 - val_acc: 0.9667\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2238e-04 - acc: 1.0000 - val_loss: 0.1436 - val_acc: 0.9667\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1917e-04 - acc: 1.0000 - val_loss: 0.1437 - val_acc: 0.9667\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2853e-04 - acc: 1.0000 - val_loss: 0.1438 - val_acc: 0.9667\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.8898e-05 - acc: 1.0000 - val_loss: 0.1440 - val_acc: 0.9667\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4564e-04 - acc: 1.0000 - val_loss: 0.1441 - val_acc: 0.9667\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1933e-04 - acc: 1.0000 - val_loss: 0.1443 - val_acc: 0.9667\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.0421e-04 - acc: 1.0000 - val_loss: 0.1445 - val_acc: 0.9667\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1685e-04 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 0.9667\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.8236e-04 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 0.9667\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.7343e-04 - acc: 1.0000 - val_loss: 0.1450 - val_acc: 0.9667\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.4631e-04 - acc: 1.0000 - val_loss: 0.1453 - val_acc: 0.9667\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.9854e-05 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 0.9667\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.6683e-05 - acc: 1.0000 - val_loss: 0.1457 - val_acc: 0.9667\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4830e-04 - acc: 1.0000 - val_loss: 0.1460 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.1812e-05 - acc: 1.0000 - val_loss: 0.1462 - val_acc: 0.9667\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 8.1386e-05 - acc: 1.0000 - val_loss: 0.1465 - val_acc: 0.9667\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.3166e-05 - acc: 1.0000 - val_loss: 0.1467 - val_acc: 0.9667\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.0970e-04 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 0.9667\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.5811e-05 - acc: 1.0000 - val_loss: 0.1471 - val_acc: 0.9667\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.6862e-05 - acc: 1.0000 - val_loss: 0.1473 - val_acc: 0.9667\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.7842e-05 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 0.9667\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.3218e-05 - acc: 1.0000 - val_loss: 0.1475 - val_acc: 0.9667\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 6.0429e-05 - acc: 1.0000 - val_loss: 0.1476 - val_acc: 0.9667\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.7544e-05 - acc: 1.0000 - val_loss: 0.1477 - val_acc: 0.9667\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 5.8715e-05 - acc: 1.0000 - val_loss: 0.1478 - val_acc: 0.9667\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.2846e-05 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9667\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.0957e-04 - acc: 1.0000 - val_loss: 0.1478 - val_acc: 0.9667\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.7475e-05 - acc: 1.0000 - val_loss: 0.1478 - val_acc: 0.9667\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.8121e-05 - acc: 1.0000 - val_loss: 0.1478 - val_acc: 0.9667\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.1850e-05 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9667\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.7920e-04 - acc: 1.0000 - val_loss: 0.1477 - val_acc: 0.9667\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.9332e-05 - acc: 1.0000 - val_loss: 0.1475 - val_acc: 0.9667\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.2932e-05 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 0.9667\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.8331e-05 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 0.9667\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.4385e-04 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 0.9667\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.8817e-05 - acc: 1.0000 - val_loss: 0.1461 - val_acc: 0.9667\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.2301e-05 - acc: 1.0000 - val_loss: 0.1454 - val_acc: 0.9667\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.5824e-05 - acc: 1.0000 - val_loss: 0.1450 - val_acc: 0.9667\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 120 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0936 - acc: 0.9750 - val_loss: 4.4442e-05 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0511 - acc: 0.9833 - val_loss: 1.8429e-04 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 8.5652e-04 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0356 - acc: 0.9917 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0283 - acc: 0.9917 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0340 - acc: 0.9917 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0156 - acc: 0.9917 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0149 - acc: 0.9917 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 5.2361e-04 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 4.1841e-04 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0077 - acc: 0.9917 - val_loss: 4.0907e-04 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 1s 6ms/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 3.5863e-04 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 2.5192e-04 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.6976e-04 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 1.3987e-04 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.2524e-04 - acc: 1.0000 - val_loss: 1.4645e-04 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 1.7361e-04 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 1.8620e-04 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.0068 - acc: 0.9917 - val_loss: 1.6677e-04 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.8356e-04 - acc: 1.0000 - val_loss: 1.6091e-04 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.5308e-04 - acc: 1.0000 - val_loss: 1.6740e-04 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.5755e-04 - acc: 1.0000 - val_loss: 1.7923e-04 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.7521e-04 - acc: 1.0000 - val_loss: 1.9445e-04 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.8288e-04 - acc: 1.0000 - val_loss: 2.1673e-04 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.6837e-04 - acc: 1.0000 - val_loss: 2.3903e-04 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.8389e-04 - acc: 1.0000 - val_loss: 2.5856e-04 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 3.3955e-04 - acc: 1.0000 - val_loss: 2.7112e-04 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4082e-04 - acc: 1.0000 - val_loss: 2.7938e-04 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.2283e-04 - acc: 1.0000 - val_loss: 2.8176e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.0384e-04 - acc: 1.0000 - val_loss: 2.7624e-04 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.8312e-04 - acc: 1.0000 - val_loss: 2.7086e-04 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.2188e-04 - acc: 1.0000 - val_loss: 2.6523e-04 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.6887e-04 - acc: 1.0000 - val_loss: 2.5856e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.2014e-04 - acc: 1.0000 - val_loss: 2.4961e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.6454e-04 - acc: 1.0000 - val_loss: 2.8127e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.7624e-04 - acc: 1.0000 - val_loss: 3.5833e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2824e-04 - acc: 1.0000 - val_loss: 4.3545e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.8601e-04 - acc: 1.0000 - val_loss: 5.0755e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.1287e-04 - acc: 1.0000 - val_loss: 5.5463e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.6236e-04 - acc: 1.0000 - val_loss: 5.8261e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.4577e-04 - acc: 1.0000 - val_loss: 5.6504e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.5589e-04 - acc: 1.0000 - val_loss: 5.3769e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4230e-04 - acc: 1.0000 - val_loss: 5.1058e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 3.7892e-04 - acc: 1.0000 - val_loss: 4.8151e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.9587e-04 - acc: 1.0000 - val_loss: 4.5847e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.8347e-04 - acc: 1.0000 - val_loss: 4.3058e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.8619e-04 - acc: 1.0000 - val_loss: 4.0159e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.9622e-04 - acc: 1.0000 - val_loss: 3.7133e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.9134e-04 - acc: 1.0000 - val_loss: 3.4609e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.7538e-04 - acc: 1.0000 - val_loss: 3.2318e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 2.0200e-04 - acc: 1.0000 - val_loss: 3.0409e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2328e-04 - acc: 1.0000 - val_loss: 2.8794e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.3755e-04 - acc: 1.0000 - val_loss: 2.7523e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.5462e-04 - acc: 1.0000 - val_loss: 2.6490e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2200e-04 - acc: 1.0000 - val_loss: 2.5653e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2542e-04 - acc: 1.0000 - val_loss: 2.4878e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2860e-04 - acc: 1.0000 - val_loss: 2.4150e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.0020e-04 - acc: 1.0000 - val_loss: 2.3485e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.1515e-04 - acc: 1.0000 - val_loss: 2.2731e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.0600e-05 - acc: 1.0000 - val_loss: 2.1969e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 9.5862e-05 - acc: 1.0000 - val_loss: 2.1256e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.7463e-05 - acc: 1.0000 - val_loss: 2.0614e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.6633e-04 - acc: 1.0000 - val_loss: 2.0052e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.5975e-05 - acc: 1.0000 - val_loss: 1.9508e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4928e-04 - acc: 1.0000 - val_loss: 1.9117e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.8102e-05 - acc: 1.0000 - val_loss: 1.8795e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.9665e-05 - acc: 1.0000 - val_loss: 1.8482e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.5261e-04 - acc: 1.0000 - val_loss: 1.8220e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.0231e-05 - acc: 1.0000 - val_loss: 1.7949e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.7274e-05 - acc: 1.0000 - val_loss: 1.7649e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.6547e-05 - acc: 1.0000 - val_loss: 1.7404e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 2.0281e-04 - acc: 1.0000 - val_loss: 1.7172e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.7203e-05 - acc: 1.0000 - val_loss: 1.6960e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2413e-04 - acc: 1.0000 - val_loss: 1.6723e-04 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.0723e-05 - acc: 1.0000 - val_loss: 1.6512e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.0501e-04 - acc: 1.0000 - val_loss: 1.6610e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.0510e-05 - acc: 1.0000 - val_loss: 1.6993e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.3868e-05 - acc: 1.0000 - val_loss: 1.7313e-04 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 3.1348e-05 - acc: 1.0000 - val_loss: 1.7544e-04 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 6.5508e-05 - acc: 1.0000 - val_loss: 1.7778e-04 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.9849e-05 - acc: 1.0000 - val_loss: 1.7935e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.6457e-05 - acc: 1.0000 - val_loss: 1.8028e-04 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 5.6670e-05 - acc: 1.0000 - val_loss: 1.8038e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 5.4088e-05 - acc: 1.0000 - val_loss: 1.7994e-04 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 4.5638e-05 - acc: 1.0000 - val_loss: 1.7937e-04 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.7373e-05 - acc: 1.0000 - val_loss: 1.7875e-04 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.2698e-04 - acc: 1.0000 - val_loss: 1.7812e-04 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 7.1050e-05 - acc: 1.0000 - val_loss: 1.7749e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.0280e-04 - acc: 1.0000 - val_loss: 1.7574e-04 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 8.9690e-05 - acc: 1.0000 - val_loss: 1.7390e-04 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.7719e-05 - acc: 1.0000 - val_loss: 1.7191e-04 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.3658e-05 - acc: 1.0000 - val_loss: 1.7034e-04 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.5733e-05 - acc: 1.0000 - val_loss: 1.6864e-04 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 5.0985e-05 - acc: 1.0000 - val_loss: 1.6639e-04 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4427e-04 - acc: 1.0000 - val_loss: 1.6221e-04 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 4.0128e-05 - acc: 1.0000 - val_loss: 1.5907e-04 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 1.4079e-04 - acc: 1.0000 - val_loss: 1.5722e-04 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.3604e-04 - acc: 1.0000 - val_loss: 1.5356e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "for train, test in kfold.split(x, y):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f\"Training for fold {fold_no} ...\")\n",
    "    #history = model.fit(x_r[train], y_r[train], epochs=100, batch_size=100, validation_data= (x_r[test], y_r[test]) )\n",
    "    #history = model.fit(train, epochs=100, batch_size=100, validation_data= test )\n",
    "    history = model.fit(x[train], y[train], epochs=100, batch_size=100, verbose=1, validation_data= (x[test], y[test]))\n",
    "    #scores = model.evaluate(x[test], y[test], verbose=0)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    #Results = appendHist(Results, history)\n",
    "    #Results_Acc = Results_Acc.append(history.history['accuracy'])\n",
    "    Results['accuracy'].append(history.history['acc'])\n",
    "    Results['loss'].append(history.history['loss'])\n",
    "    Results['val_accuracy'].append(history.history['val_acc'])\n",
    "    Results['val_loss'].append(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Results['accuracy']\n",
    "B = Results['val_accuracy']\n",
    "C = Results['loss']\n",
    "D = Results['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ac = np.array([A[0], A[1], A[2]])\n",
    "TrainAcc = np.concatenate((A[0], A[1],A[2]), axis=0)\n",
    "TestAcc = np.concatenate((B[0], B[1],B[2]), axis=0)\n",
    "Trainloss = np.concatenate((C[0], C[1],C[2]), axis=0)\n",
    "Testloss = np.concatenate((D[0], D[1],D[2]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x78a0c43248>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "#fig.suptitle('Model Accuracy and Loss')\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(12)\n",
    "ax1.plot(TrainAcc,'b')\n",
    "ax1.plot(TestAcc,'r-')\n",
    "ax1.set_ylim(-0.2, 1.2)\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set(xlabel='Epochs',ylabel='Accuracy')\n",
    "ax1.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "ax2.plot(Trainloss,'b')\n",
    "ax2.plot(Testloss,'r-')\n",
    "#ax2.set_ylim(-0.2, 1.2)\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set(xlabel='Epochs',ylabel='Loss')\n",
    "#plt.ylabel('Accuracy')\n",
    "\n",
    "ax2.legend(['Train Loss', 'Test Loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 0s - loss: 6.4397e-05 - acc: 1.0000\n",
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(x, y, verbose=2)\n",
    "print(\"Model Accuracy: {:5.2f}%\".format(100 * acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1_30_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthikeyan\\GUI_BionicHand\\model1_30_5\n"
     ]
    }
   ],
   "source": [
    "direct = os.getcwd()\n",
    "Model_Fname = direct+'\\model1_30_5'\n",
    "print(Model_Fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\Karthikeyan\\GUI_BionicHand/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-6d16b2654a2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirect\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# path to the SavedModel directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[1;34m(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     result = _freeze_saved_model(saved_model_dir, input_arrays, input_shapes,\n\u001b[1;32m--> 696\u001b[1;33m                                  output_arrays, tag_set, signature_key)\n\u001b[0m\u001b[0;32m    697\u001b[0m     return cls(\n\u001b[0;32m    698\u001b[0m         graph_def=result[0], input_tensors=result[1], output_tensors=result[2])\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py\u001b[0m in \u001b[0;36mfreeze_saved_model\u001b[1;34m(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[0;32m    184\u001b[0m   \"\"\"\n\u001b[0;32m    185\u001b[0m   \u001b[1;31m# Read SignatureDef.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m   \u001b[0mmeta_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_meta_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m   \u001b[0msignature_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_signature_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m   \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_inputs_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py\u001b[0m in \u001b[0;36mget_meta_graph_def\u001b[1;34m(saved_model_dir, tag_set)\u001b[0m\n\u001b[0;32m     58\u001b[0m   \"\"\"\n\u001b[0;32m     59\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaved_model_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(sess, tags, export_dir, import_scope, **saver_kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMetaGraphDef\u001b[0m \u001b[0massociated\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtags\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m   \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m   \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSavedModelLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msaver_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, export_dir)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_export_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variables_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_model_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     81\u001b[0m                   (export_dir,\n\u001b[0;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\Karthikeyan\\GUI_BionicHand/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(direct) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "with open('model1_30_5.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
